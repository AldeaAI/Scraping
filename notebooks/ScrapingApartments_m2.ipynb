{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce01bf-e043-4320-ae95-ad3af66dd82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_json_data(driver, url, timeout=10):\n",
    "    \"\"\"Extracts JSON data from a <script type=\"application/json\"> tag.\n",
    "\n",
    "    Args:\n",
    "        driver: Selenium WebDriver instance.\n",
    "        url: URL of the page.\n",
    "        timeout: Timeout in seconds for waiting for the page to load.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed JSON data, or None if not found or on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        wait = WebDriverWait(driver, timeout)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "        script_tags = soup.find_all(\"script\", type=\"application/json\")\n",
    "        if script_tags:\n",
    "            for script_tag in script_tags:\n",
    "                try:\n",
    "                    json_data = json.loads(script_tag.string)\n",
    "                    return json_data\n",
    "                except json.JSONDecodeError as e:\n",
    "                    logging.error(f\"JSON Decode Error on {url}: {e}\")\n",
    "                    return None\n",
    "        return None  # No script tag found\n",
    "\n",
    "    except TimeoutException:\n",
    "        logging.error(f\"Timeout on {url}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error extracting JSON on {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_property_details(driver, url, timeout=10):\n",
    "    \"\"\"Extracts specific property details from the JSON data.\n",
    "\n",
    "    Args:\n",
    "        driver: Selenium WebDriver instance.\n",
    "        url: URL of the property page.\n",
    "        timeout: Timeout in seconds.\n",
    "\n",
    "    Returns:\n",
    "        dict: Extracted property details, or None if not found or on error.\n",
    "    \"\"\"\n",
    "    json_data = extract_json_data(driver, url, timeout)\n",
    "    if json_data and 'props' in json_data and 'initialProps' in json_data['props']:\n",
    "        initial_props = json_data['props']['initialProps']\n",
    "        if 'pageProps' in initial_props and 'realEstate' in initial_props['pageProps']:\n",
    "            real_estate = initial_props['pageProps']['realEstate']\n",
    "            try:\n",
    "                details = {\n",
    "                     'propertyId'   : real_estate.get('propertyId'),\n",
    "                     'propertyType' : real_estate.get('propertyType'),\n",
    "                     # 'businessType' : real_estate.get('businessType'),\n",
    "                     'salePrice'     : real_estate.get('salePrice'),\n",
    "                     'area':real_estate.get('area'),\n",
    "                     'areac':real_estate.get('areac'),\n",
    "                     'rooms':real_estate.get('rooms'),\n",
    "                     'bathrooms':real_estate.get('bathrooms'),\n",
    "                     'garages':real_estate.get('garages'),\n",
    "                     'city': real_estate.get('city'),\n",
    "                     'zone': real_estate.get('zone'),\n",
    "                     # 'sector': real_estate.get('sector'),\n",
    "                     'neighborhood':real_estate.get('neighborhood'),\n",
    "                     'commonNeighborhood':real_estate.get('commonNeighborhood'),\n",
    "                     'adminPrice': real_estate['detail'].get('adminPrice'),\n",
    "                     'companyName':real_estate.get('companyName'),\n",
    "                     'propertyState': real_estate.get('propertyState'),\n",
    "                     'coordinates': real_estate.get('coordinates'),\n",
    "                     'link':real_estate.get('link'),\n",
    "                     'builtTime':real_estate.get('builtTime'),\n",
    "                     'stratum':real_estate.get('stratum'),\n",
    "                }\n",
    "                return details\n",
    "            except (KeyError, TypeError) as e:\n",
    "                logging.error(f\"Error extracting specific data from {url}: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            logging.warning(f\"'realEstate' key not found in JSON on {url}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def get_property_links_selenium(url_main, timeout=10, limit=None):\n",
    "    \"\"\"Extracts property links and details, excluding \"proyecto\" links, and returns a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        url_main: Main URL to start scraping.\n",
    "        timeout: Timeout for Selenium waits.\n",
    "        limit: Maximum number of links to process.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame containing property details, or None on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless=new')  # Run Chrome in headless mode (no browser window)\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        driver.get(url_main)\n",
    "\n",
    "        wait = WebDriverWait(driver, timeout)\n",
    "        # Find all card headers that contain the property links\n",
    "        card_headers = wait.until(EC.presence_of_all_elements_located((By.CLASS_NAME, \"card-header\")))\n",
    "\n",
    "        links = []\n",
    "        for card_header in card_headers:\n",
    "            a_tags = card_header.find_elements(By.TAG_NAME, \"a\")\n",
    "            for a_tag in a_tags:\n",
    "                href = a_tag.get_attribute(\"href\")\n",
    "                # Exclude links containing \"proyecto\" (project/new development properties)\n",
    "                if href and \"proyecto\" not in href.lower():\n",
    "                    links.append(href)\n",
    "\n",
    "        extracted_data = []\n",
    "        for i, link in enumerate(links):\n",
    "            if limit and i >= limit:  # Stop if the limit is reached\n",
    "                break\n",
    "            logging.info(f\"Extracting data from link {i+1}/{len(links)}: {link}\")\n",
    "            data = extract_property_details(driver, link)\n",
    "            if data:\n",
    "                extracted_data.append(data)\n",
    "\n",
    "        driver.quit()\n",
    "\n",
    "        if extracted_data:  # Create a pandas DataFrame if data was extracted\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "            return df\n",
    "        else:\n",
    "            logging.info(\"No property details extracted.\")\n",
    "            return None\n",
    "\n",
    "    except TimeoutException:\n",
    "        logging.error(f\"Timed out waiting for elements after {timeout} seconds.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_url = \"https://www.metrocuadrado.com/apartaestudio-apartamento/venta/medellin/\"\n",
    "    df = get_property_links_selenium(main_url, limit=None)  # Limit for testing\n",
    "\n",
    "    if df is not None:\n",
    "        # Create filename with date\n",
    "        extraction_date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        filename = f\"listings_data_m2_{extraction_date_str}.csv\"  # Filename with date\n",
    "        df.to_csv(filename, index=False, encoding=\"utf-8\")  # Saves the dataframe to a csv file\n",
    "        print(f\"Data saved to {filename}\") #Prints the filename\n",
    "        logging.info(\"Property data saved to property_data.csv\")\n",
    "    else:\n",
    "        logging.info(\"Could not retrieve property links or create DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
